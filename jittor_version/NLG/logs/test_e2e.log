==================================================================================================== - 2025-03-25 13:05:36,874 - log
        - platform : local - 2025-03-25 13:05:36,874 - log
        - local_rank : 0 - 2025-03-25 13:05:36,874 - log
        - rank : 0 - 2025-03-25 13:05:36,874 - log
        - device : cuda - 2025-03-25 13:05:36,875 - log
        - world_size : 0 - 2025-03-25 13:05:36,875 - log
        - random_seed : 10 - 2025-03-25 13:05:36,875 - log
        - data : ./data/e2e/test.jsonl - 2025-03-25 13:05:36,875 - log
        - batch_size : 1 - 2025-03-25 13:05:36,875 - log
        - seq_len : 64 - 2025-03-25 13:05:36,875 - log
        - eval_len : 32 - 2025-03-25 13:05:36,875 - log
        - min_length : 0 - 2025-03-25 13:05:36,875 - log
        - model_card : gpt2.sm - 2025-03-25 13:05:36,875 - log
        - init_checkpoint : ./trained_models/GPT2_M/e2e/model.1050.pt - 2025-03-25 13:05:36,875 - log
        - lora_dim : 4 - 2025-03-25 13:05:36,875 - log
        - lora_alpha : 32 - 2025-03-25 13:05:36,875 - log
        - work_dir : ./trained_models/GPT2_M/e2e - 2025-03-25 13:05:36,875 - log
        - beam : 10 - 2025-03-25 13:05:36,875 - log
        - length_penalty : 0.8 - 2025-03-25 13:05:36,875 - log
        - no_repeat_ngram_size : 4 - 2025-03-25 13:05:36,875 - log
        - repetition_penalty : 1.0 - 2025-03-25 13:05:36,875 - log
        - eos_token_id : [50256, 628] - 2025-03-25 13:05:36,875 - log
        - output_file : predict.1050.b10p08r4.jsonl - 2025-03-25 13:05:36,875 - log
==================================================================================================== - 2025-03-25 13:05:36,875 - log
--------------------------------------------------test-------------------------------------------------- - 2025-03-25 13:05:36,875 - log
loading model pretrained weight. - 2025-03-25 13:05:36,994 - log
model sampling ... - 2025-03-25 13:05:37,165 - log
inference samples: 0 - 2025-03-25 13:05:37,910 - log
inference samples: 10 - 2025-03-25 13:05:43,808 - log
inference samples: 20 - 2025-03-25 13:05:49,628 - log
inference samples: 30 - 2025-03-25 13:05:55,463 - log
inference samples: 40 - 2025-03-25 13:06:01,354 - log
saving prediction file: ./trained_models/GPT2_M/e2e/predict.1050.b10p08r4.jsonl - 2025-03-25 13:06:04,296 - log
finish inference - 2025-03-25 13:06:04,296 - log
SCORES:
============== - 2025-03-25 13:06:09,973 - log
BLEU: 0.0000 - 2025-03-25 13:06:09,973 - log
NIST: 0.0367 - 2025-03-25 13:06:09,973 - log
METEOR: 0.0040 - 2025-03-25 13:06:09,973 - log
ROUGE_L: 0.0012 - 2025-03-25 13:06:09,973 - log
CIDEr: 0.0001 - 2025-03-25 13:06:09,973 - log

 - 2025-03-25 13:06:09,973 - log
SCORES:
============== - 2025-03-25 15:16:22,653 - log
BLEU: 0.0000 - 2025-03-25 15:16:22,653 - log
NIST: 0.0367 - 2025-03-25 15:16:22,654 - log
METEOR: 0.0040 - 2025-03-25 15:16:22,654 - log
ROUGE_L: 0.0012 - 2025-03-25 15:16:22,654 - log
CIDEr: 0.0001 - 2025-03-25 15:16:22,654 - log

 - 2025-03-25 15:16:22,654 - log
SCORES:
============== - 2025-03-25 15:16:57,122 - log
BLEU: 0.0000 - 2025-03-25 15:16:57,122 - log
NIST: 0.0367 - 2025-03-25 15:16:57,122 - log
METEOR: 0.0040 - 2025-03-25 15:16:57,122 - log
ROUGE_L: 0.0012 - 2025-03-25 15:16:57,122 - log
CIDEr: 0.0001 - 2025-03-25 15:16:57,122 - log

 - 2025-03-25 15:16:57,122 - log
SCORES:
============== - 2025-03-25 15:21:28,336 - log
BLEU: 0.0000 - 2025-03-25 15:21:28,336 - log
NIST: 0.0367 - 2025-03-25 15:21:28,336 - log
METEOR: 0.0040 - 2025-03-25 15:21:28,336 - log
ROUGE_L: 0.0012 - 2025-03-25 15:21:28,336 - log
CIDEr: 0.0001 - 2025-03-25 15:21:28,336 - log

 - 2025-03-25 15:21:28,336 - log
SCORES:
============== - 2025-03-25 15:23:28,952 - log
BLEU: 0.0000 - 2025-03-25 15:23:28,952 - log
NIST: 0.0367 - 2025-03-25 15:23:28,952 - log
METEOR: 0.0040 - 2025-03-25 15:23:28,952 - log
ROUGE_L: 0.0012 - 2025-03-25 15:23:28,952 - log
CIDEr: 0.0001 - 2025-03-25 15:23:28,952 - log

 - 2025-03-25 15:23:28,952 - log
SCORES:
============== - 2025-03-25 15:26:29,265 - log
BLEU: 0.0000 - 2025-03-25 15:26:29,265 - log
NIST: 0.0367 - 2025-03-25 15:26:29,265 - log
METEOR: 0.0040 - 2025-03-25 15:26:29,265 - log
ROUGE_L: 0.0012 - 2025-03-25 15:26:29,265 - log
CIDEr: 0.0001 - 2025-03-25 15:26:29,265 - log

 - 2025-03-25 15:26:29,265 - log
==================================================================================================== - 2025-03-25 15:28:01,630 - log
        - random_seed : 2025 - 2025-03-25 15:28:01,630 - log
        - data : ./data/e2e/test.jsonl - 2025-03-25 15:28:01,630 - log
        - batch_size : 1 - 2025-03-25 15:28:01,630 - log
        - seq_len : 64 - 2025-03-25 15:28:01,630 - log
        - eval_len : 32 - 2025-03-25 15:28:01,630 - log
        - min_length : 0 - 2025-03-25 15:28:01,630 - log
        - model_card : gpt2.sm - 2025-03-25 15:28:01,630 - log
        - init_checkpoint : ./trained_models/GPT2_M/e2e/model.1050.pt - 2025-03-25 15:28:01,630 - log
        - lora_dim : 4 - 2025-03-25 15:28:01,631 - log
        - lora_alpha : 32 - 2025-03-25 15:28:01,631 - log
        - work_dir : ./trained_models/GPT2_M/e2e - 2025-03-25 15:28:01,631 - log
        - beam : 10 - 2025-03-25 15:28:01,631 - log
        - length_penalty : 0.8 - 2025-03-25 15:28:01,631 - log
        - no_repeat_ngram_size : 4 - 2025-03-25 15:28:01,631 - log
        - repetition_penalty : 1.0 - 2025-03-25 15:28:01,631 - log
        - eos_token_id : [50256, 628] - 2025-03-25 15:28:01,631 - log
        - output_file : predict.1050.b10p08r4.jsonl - 2025-03-25 15:28:01,631 - log
        - device : cuda - 2025-03-25 15:28:01,631 - log
==================================================================================================== - 2025-03-25 15:28:01,631 - log
--------------------------------------------------test-------------------------------------------------- - 2025-03-25 15:28:01,631 - log
loading model pretrained weight. - 2025-03-25 15:28:01,733 - log
model sampling ... - 2025-03-25 15:28:01,896 - log
inference samples: 0 - 2025-03-25 15:28:02,634 - log
inference samples: 10 - 2025-03-25 15:28:08,431 - log
inference samples: 20 - 2025-03-25 15:28:14,261 - log
inference samples: 30 - 2025-03-25 15:28:20,136 - log
inference samples: 40 - 2025-03-25 15:28:27,393 - log
saving prediction file: ./trained_models/GPT2_M/e2e/predict.1050.b10p08r4.jsonl - 2025-03-25 15:28:30,333 - log
finish inference - 2025-03-25 15:28:30,333 - log
SCORES:
============== - 2025-03-25 15:28:35,905 - log
BLEU: 0.0000 - 2025-03-25 15:28:35,905 - log
NIST: 0.0528 - 2025-03-25 15:28:35,905 - log
METEOR: 0.0032 - 2025-03-25 15:28:35,905 - log
ROUGE_L: 0.0011 - 2025-03-25 15:28:35,905 - log
CIDEr: 0.0000 - 2025-03-25 15:28:35,905 - log

 - 2025-03-25 15:28:35,905 - log
==================================================================================================== - 2025-03-25 15:30:53,735 - log
        - random_seed : 2025 - 2025-03-25 15:30:53,735 - log
        - data : ./data/e2e/test.jsonl - 2025-03-25 15:30:53,735 - log
        - batch_size : 1 - 2025-03-25 15:30:53,735 - log
        - seq_len : 64 - 2025-03-25 15:30:53,735 - log
        - eval_len : 32 - 2025-03-25 15:30:53,735 - log
        - min_length : 0 - 2025-03-25 15:30:53,735 - log
        - model_card : gpt2.sm - 2025-03-25 15:30:53,735 - log
        - init_checkpoint : ./trained_models/GPT2_M/e2e/model.1050.pt - 2025-03-25 15:30:53,735 - log
        - lora_dim : 4 - 2025-03-25 15:30:53,735 - log
        - lora_alpha : 32 - 2025-03-25 15:30:53,735 - log
        - work_dir : ./trained_models/GPT2_M/e2e - 2025-03-25 15:30:53,735 - log
        - beam : 10 - 2025-03-25 15:30:53,735 - log
        - length_penalty : 0.8 - 2025-03-25 15:30:53,735 - log
        - no_repeat_ngram_size : 4 - 2025-03-25 15:30:53,735 - log
        - repetition_penalty : 1.0 - 2025-03-25 15:30:53,735 - log
        - eos_token_id : [50256, 628] - 2025-03-25 15:30:53,735 - log
        - output_file : predict.1050.b10p08r4.jsonl - 2025-03-25 15:30:53,735 - log
        - device : cuda - 2025-03-25 15:30:53,735 - log
==================================================================================================== - 2025-03-25 15:30:53,735 - log
--------------------------------------------------test-------------------------------------------------- - 2025-03-25 15:30:53,736 - log
loading model pretrained weight. - 2025-03-25 15:30:53,854 - log
model sampling ... - 2025-03-25 15:30:54,028 - log
inference samples: 0 - 2025-03-25 15:30:54,795 - log
inference samples: 10 - 2025-03-25 15:31:00,729 - log
inference samples: 20 - 2025-03-25 15:31:06,645 - log
inference samples: 30 - 2025-03-25 15:31:12,563 - log
inference samples: 40 - 2025-03-25 15:31:18,533 - log
saving prediction file: ./trained_models/GPT2_M/e2e/predict.1050.b10p08r4.jsonl - 2025-03-25 15:31:21,468 - log
finish inference - 2025-03-25 15:31:21,469 - log
SCORES:
============== - 2025-03-25 15:31:27,120 - log
BLEU: 0.0000 - 2025-03-25 15:31:27,120 - log
NIST: 0.0541 - 2025-03-25 15:31:27,120 - log
METEOR: 0.0025 - 2025-03-25 15:31:27,120 - log
ROUGE_L: 0.0000 - 2025-03-25 15:31:27,120 - log
CIDEr: 0.0000 - 2025-03-25 15:31:27,120 - log

 - 2025-03-25 15:31:27,120 - log
==================================================================================================== - 2025-03-25 15:38:10,622 - log
        - random_seed : 2025 - 2025-03-25 15:38:10,633 - log
        - data : ./data/e2e/test.jsonl - 2025-03-25 15:38:10,633 - log
        - batch_size : 1 - 2025-03-25 15:38:10,633 - log
        - seq_len : 64 - 2025-03-25 15:38:10,633 - log
        - eval_len : 32 - 2025-03-25 15:38:10,633 - log
        - min_length : 0 - 2025-03-25 15:38:10,633 - log
        - model_card : gpt2.sm - 2025-03-25 15:38:10,633 - log
        - init_checkpoint : ./trained_models/GPT2_M/e2e/model.1050.pt - 2025-03-25 15:38:10,633 - log
        - lora_dim : 4 - 2025-03-25 15:38:10,633 - log
        - lora_alpha : 32 - 2025-03-25 15:38:10,633 - log
        - work_dir : ./trained_models/GPT2_M/e2e - 2025-03-25 15:38:10,633 - log
        - beam : 10 - 2025-03-25 15:38:10,633 - log
        - length_penalty : 0.8 - 2025-03-25 15:38:10,633 - log
        - no_repeat_ngram_size : 4 - 2025-03-25 15:38:10,633 - log
        - repetition_penalty : 1.0 - 2025-03-25 15:38:10,633 - log
        - eos_token_id : [50256, 628] - 2025-03-25 15:38:10,633 - log
        - output_file : predict.1050.b10p08r4.jsonl - 2025-03-25 15:38:10,633 - log
        - device : cuda - 2025-03-25 15:38:10,633 - log
==================================================================================================== - 2025-03-25 15:38:10,633 - log
--------------------------------------------------test-------------------------------------------------- - 2025-03-25 15:38:10,633 - log
loading model pretrained weight. - 2025-03-25 15:38:10,743 - log
model sampling ... - 2025-03-25 15:38:10,922 - log
inference samples: 0 - 2025-03-25 15:38:11,704 - log
inference samples: 10 - 2025-03-25 15:38:17,617 - log
inference samples: 20 - 2025-03-25 15:38:23,482 - log
inference samples: 30 - 2025-03-25 15:38:29,390 - log
inference samples: 40 - 2025-03-25 15:38:35,298 - log
saving prediction file: ./trained_models/GPT2_M/e2e/predict.1050.b10p08r4.jsonl - 2025-03-25 15:38:38,251 - log
finish inference - 2025-03-25 15:38:38,252 - log
SCORES:
============== - 2025-03-25 15:38:44,094 - log
BLEU: 0.0000 - 2025-03-25 15:38:44,094 - log
NIST: 0.0629 - 2025-03-25 15:38:44,094 - log
METEOR: 0.0024 - 2025-03-25 15:38:44,094 - log
ROUGE_L: 0.0000 - 2025-03-25 15:38:44,094 - log
CIDEr: 0.0000 - 2025-03-25 15:38:44,094 - log

 - 2025-03-25 15:38:44,094 - log
==================================================================================================== - 2025-03-25 15:44:02,970 - log
        - random_seed : 2025 - 2025-03-25 15:44:02,970 - log
        - data : ./data/e2e/test.jsonl - 2025-03-25 15:44:02,970 - log
        - batch_size : 1 - 2025-03-25 15:44:02,970 - log
        - seq_len : 64 - 2025-03-25 15:44:02,970 - log
        - eval_len : 32 - 2025-03-25 15:44:02,970 - log
        - min_length : 0 - 2025-03-25 15:44:02,970 - log
        - model_card : gpt2.sm - 2025-03-25 15:44:02,970 - log
        - init_checkpoint : ./trained_models/GPT2_M/e2e/model.1050.pt - 2025-03-25 15:44:02,970 - log
        - lora_dim : 4 - 2025-03-25 15:44:02,970 - log
        - lora_alpha : 32 - 2025-03-25 15:44:02,970 - log
        - work_dir : ./trained_models/GPT2_M/e2e - 2025-03-25 15:44:02,970 - log
        - beam : 10 - 2025-03-25 15:44:02,970 - log
        - length_penalty : 0.8 - 2025-03-25 15:44:02,970 - log
        - no_repeat_ngram_size : 4 - 2025-03-25 15:44:02,971 - log
        - repetition_penalty : 1.0 - 2025-03-25 15:44:02,971 - log
        - eos_token_id : [50256, 628] - 2025-03-25 15:44:02,971 - log
        - output_file : predict.1050.b10p08r4.jsonl - 2025-03-25 15:44:02,971 - log
        - device : cuda - 2025-03-25 15:44:02,971 - log
==================================================================================================== - 2025-03-25 15:44:02,971 - log
--------------------------------------------------test-------------------------------------------------- - 2025-03-25 15:44:02,971 - log
loading model pretrained weight. - 2025-03-25 15:44:03,080 - log
model sampling ... - 2025-03-25 15:44:03,262 - log
inference samples: 0 - 2025-03-25 15:44:04,010 - log
inference samples: 10 - 2025-03-25 15:44:09,967 - log
inference samples: 20 - 2025-03-25 15:44:15,901 - log
inference samples: 30 - 2025-03-25 15:44:21,835 - log
inference samples: 40 - 2025-03-25 15:44:27,786 - log
saving prediction file: ./trained_models/GPT2_M/e2e/predict.1050.b10p08r4.jsonl - 2025-03-25 15:44:30,753 - log
finish inference - 2025-03-25 15:44:30,754 - log
==================================================================================================== - 2025-03-25 15:49:17,683 - log
        - random_seed : 2025 - 2025-03-25 15:49:17,683 - log
        - data : ./data/e2e/test.jsonl - 2025-03-25 15:49:17,683 - log
        - batch_size : 1 - 2025-03-25 15:49:17,683 - log
        - seq_len : 64 - 2025-03-25 15:49:17,683 - log
        - eval_len : 32 - 2025-03-25 15:49:17,683 - log
        - min_length : 0 - 2025-03-25 15:49:17,683 - log
        - model_card : gpt2.sm - 2025-03-25 15:49:17,683 - log
        - init_checkpoint : ./trained_models/GPT2_M/e2e/model.1050.pt - 2025-03-25 15:49:17,683 - log
        - lora_dim : 4 - 2025-03-25 15:49:17,683 - log
        - lora_alpha : 32 - 2025-03-25 15:49:17,683 - log
        - work_dir : ./trained_models/GPT2_M/e2e - 2025-03-25 15:49:17,683 - log
        - beam : 10 - 2025-03-25 15:49:17,683 - log
        - length_penalty : 0.8 - 2025-03-25 15:49:17,683 - log
        - no_repeat_ngram_size : 4 - 2025-03-25 15:49:17,683 - log
        - repetition_penalty : 1.0 - 2025-03-25 15:49:17,683 - log
        - eos_token_id : [50256, 628] - 2025-03-25 15:49:17,683 - log
        - output_file : predict.1050.b10p08r4.jsonl - 2025-03-25 15:49:17,683 - log
        - device : cuda - 2025-03-25 15:49:17,683 - log
==================================================================================================== - 2025-03-25 15:49:17,683 - log
--------------------------------------------------test-------------------------------------------------- - 2025-03-25 15:49:17,683 - log
loading model pretrained weight. - 2025-03-25 15:49:17,793 - log
model sampling ... - 2025-03-25 15:49:17,976 - log
inference samples: 0 - 2025-03-25 15:49:18,748 - log
inference samples: 10 - 2025-03-25 15:49:24,723 - log
inference samples: 20 - 2025-03-25 15:49:30,664 - log
inference samples: 30 - 2025-03-25 15:49:36,664 - log
inference samples: 40 - 2025-03-25 15:49:42,625 - log
saving prediction file: ./trained_models/GPT2_M/e2e/predict.1050.b10p08r4.jsonl - 2025-03-25 15:49:45,600 - log
finish inference - 2025-03-25 15:49:45,601 - log
==================================================================================================== - 2025-03-25 15:59:46,248 - log
        - random_seed : 2025 - 2025-03-25 15:59:46,248 - log
        - data : ./data/e2e/test.jsonl - 2025-03-25 15:59:46,248 - log
        - batch_size : 1 - 2025-03-25 15:59:46,248 - log
        - seq_len : 64 - 2025-03-25 15:59:46,248 - log
        - eval_len : 32 - 2025-03-25 15:59:46,248 - log
        - min_length : 0 - 2025-03-25 15:59:46,248 - log
        - model_card : gpt2.sm - 2025-03-25 15:59:46,248 - log
        - init_checkpoint : ./trained_models/GPT2_M/e2e/model.1050.pt - 2025-03-25 15:59:46,248 - log
        - lora_dim : 4 - 2025-03-25 15:59:46,248 - log
        - lora_alpha : 32 - 2025-03-25 15:59:46,248 - log
        - work_dir : ./trained_models/GPT2_M/e2e - 2025-03-25 15:59:46,249 - log
        - beam : 10 - 2025-03-25 15:59:46,249 - log
        - length_penalty : 0.8 - 2025-03-25 15:59:46,249 - log
        - no_repeat_ngram_size : 4 - 2025-03-25 15:59:46,249 - log
        - repetition_penalty : 1.0 - 2025-03-25 15:59:46,249 - log
        - eos_token_id : [50256, 628] - 2025-03-25 15:59:46,249 - log
        - output_file : predict.1050.b10p08r4.jsonl - 2025-03-25 15:59:46,249 - log
        - device : cuda - 2025-03-25 15:59:46,249 - log
==================================================================================================== - 2025-03-25 15:59:46,249 - log
--------------------------------------------------test-------------------------------------------------- - 2025-03-25 15:59:46,249 - log
loading model pretrained weight. - 2025-03-25 15:59:46,356 - log
model sampling ... - 2025-03-25 15:59:46,538 - log
inference samples: 0 - 2025-03-25 15:59:47,289 - log
inference samples: 10 - 2025-03-25 15:59:53,189 - log
inference samples: 20 - 2025-03-25 15:59:59,102 - log
inference samples: 30 - 2025-03-25 16:00:05,005 - log
inference samples: 40 - 2025-03-25 16:00:10,955 - log
saving prediction file: ./trained_models/GPT2_M/e2e/predict.1050.b10p08r4.jsonl - 2025-03-25 16:00:13,923 - log
finish inference - 2025-03-25 16:00:13,923 - log
==================================================================================================== - 2025-03-25 17:06:29,854 - log
        - random_seed : 2025 - 2025-03-25 17:06:29,854 - log
        - data : ./data/e2e/test.jsonl - 2025-03-25 17:06:29,854 - log
        - batch_size : 1 - 2025-03-25 17:06:29,854 - log
        - seq_len : 64 - 2025-03-25 17:06:29,854 - log
        - eval_len : 32 - 2025-03-25 17:06:29,854 - log
        - min_length : 0 - 2025-03-25 17:06:29,854 - log
        - model_card : gpt2.sm - 2025-03-25 17:06:29,854 - log
        - init_checkpoint : ./trained_models/GPT2_M/e2e/model.1050.pt - 2025-03-25 17:06:29,854 - log
        - lora_dim : 4 - 2025-03-25 17:06:29,854 - log
        - lora_alpha : 32 - 2025-03-25 17:06:29,854 - log
        - work_dir : ./trained_models/GPT2_M/e2e - 2025-03-25 17:06:29,854 - log
        - beam : 10 - 2025-03-25 17:06:29,854 - log
        - length_penalty : 0.8 - 2025-03-25 17:06:29,854 - log
        - no_repeat_ngram_size : 4 - 2025-03-25 17:06:29,854 - log
        - repetition_penalty : 1.0 - 2025-03-25 17:06:29,854 - log
        - eos_token_id : [50256, 628] - 2025-03-25 17:06:29,854 - log
        - output_file : predict.1050.b10p08r4.jsonl - 2025-03-25 17:06:29,854 - log
        - device : cuda - 2025-03-25 17:06:29,854 - log
==================================================================================================== - 2025-03-25 17:06:29,854 - log
--------------------------------------------------test-------------------------------------------------- - 2025-03-25 17:06:29,854 - log
loading model pretrained weight. - 2025-03-25 17:06:29,961 - log
model sampling ... - 2025-03-25 17:06:30,161 - log
inference samples: 0 - 2025-03-25 17:06:30,966 - log
inference samples: 10 - 2025-03-25 17:06:36,893 - log
inference samples: 20 - 2025-03-25 17:06:42,865 - log
inference samples: 30 - 2025-03-25 17:06:48,858 - log
inference samples: 40 - 2025-03-25 17:06:54,888 - log
saving prediction file: ./trained_models/GPT2_M/e2e/predict.1050.b10p08r4.jsonl - 2025-03-25 17:06:57,868 - log
finish inference - 2025-03-25 17:06:57,868 - log
==================================================================================================== - 2025-03-25 17:11:43,384 - log
        - random_seed : 2025 - 2025-03-25 17:11:43,384 - log
        - data : ./data/e2e/test.jsonl - 2025-03-25 17:11:43,384 - log
        - batch_size : 1 - 2025-03-25 17:11:43,384 - log
        - seq_len : 64 - 2025-03-25 17:11:43,384 - log
        - eval_len : 32 - 2025-03-25 17:11:43,384 - log
        - min_length : 0 - 2025-03-25 17:11:43,384 - log
        - model_card : gpt2.sm - 2025-03-25 17:11:43,384 - log
        - init_checkpoint : ./trained_models/GPT2_M/e2e/model.1050.pt - 2025-03-25 17:11:43,385 - log
        - lora_dim : 4 - 2025-03-25 17:11:43,385 - log
        - lora_alpha : 32 - 2025-03-25 17:11:43,385 - log
        - work_dir : ./trained_models/GPT2_M/e2e - 2025-03-25 17:11:43,385 - log
        - beam : 10 - 2025-03-25 17:11:43,385 - log
        - length_penalty : 0.8 - 2025-03-25 17:11:43,385 - log
        - no_repeat_ngram_size : 4 - 2025-03-25 17:11:43,385 - log
        - repetition_penalty : 1.0 - 2025-03-25 17:11:43,385 - log
        - eos_token_id : [50256, 628] - 2025-03-25 17:11:43,385 - log
        - output_file : predict.1050.b10p08r4.jsonl - 2025-03-25 17:11:43,385 - log
        - device : cuda - 2025-03-25 17:11:43,385 - log
==================================================================================================== - 2025-03-25 17:11:43,385 - log
--------------------------------------------------test-------------------------------------------------- - 2025-03-25 17:11:43,385 - log
loading model pretrained weight. - 2025-03-25 17:11:43,497 - log
model sampling ... - 2025-03-25 17:11:43,687 - log
inference samples: 0 - 2025-03-25 17:11:44,483 - log
inference samples: 10 - 2025-03-25 17:11:50,497 - log
inference samples: 20 - 2025-03-25 17:11:56,500 - log
inference samples: 30 - 2025-03-25 17:12:02,496 - log
inference samples: 40 - 2025-03-25 17:12:08,531 - log
saving prediction file: ./trained_models/GPT2_M/e2e/predict.1050.b10p08r4.jsonl - 2025-03-25 17:12:11,564 - log
finish inference - 2025-03-25 17:12:11,564 - log
==================================================================================================== - 2025-03-25 21:52:12,390 - log
        - random_seed : 2025 - 2025-03-25 21:52:12,393 - log
        - data : ./data/e2e/test.jsonl - 2025-03-25 21:52:12,393 - log
        - batch_size : 1 - 2025-03-25 21:52:12,394 - log
        - seq_len : 64 - 2025-03-25 21:52:12,394 - log
        - eval_len : 32 - 2025-03-25 21:52:12,394 - log
        - min_length : 0 - 2025-03-25 21:52:12,394 - log
        - model_card : gpt2.sm - 2025-03-25 21:52:12,394 - log
        - init_checkpoint : ./trained_models/GPT2_M/e2e/model.1050.pt - 2025-03-25 21:52:12,394 - log
        - lora_dim : 4 - 2025-03-25 21:52:12,394 - log
        - lora_alpha : 32 - 2025-03-25 21:52:12,394 - log
        - work_dir : ./trained_models/GPT2_M/e2e - 2025-03-25 21:52:12,394 - log
        - beam : 10 - 2025-03-25 21:52:12,394 - log
        - length_penalty : 0.8 - 2025-03-25 21:52:12,394 - log
        - no_repeat_ngram_size : 4 - 2025-03-25 21:52:12,394 - log
        - repetition_penalty : 1.0 - 2025-03-25 21:52:12,394 - log
        - eos_token_id : [50256, 628] - 2025-03-25 21:52:12,394 - log
        - output_file : predict.1050.b10p08r4.jsonl - 2025-03-25 21:52:12,394 - log
        - device : cuda - 2025-03-25 21:52:12,394 - log
==================================================================================================== - 2025-03-25 21:52:12,394 - log
--------------------------------------------------test-------------------------------------------------- - 2025-03-25 21:52:12,394 - log
loading model pretrained weight. - 2025-03-25 21:52:12,503 - log
model sampling ... - 2025-03-25 21:52:12,675 - log
inference samples: 0 - 2025-03-25 21:52:14,806 - log
inference samples: 10 - 2025-03-25 21:52:20,611 - log
inference samples: 20 - 2025-03-25 21:52:26,398 - log
inference samples: 30 - 2025-03-25 21:52:32,197 - log
inference samples: 40 - 2025-03-25 21:52:38,019 - log
saving prediction file: ./trained_models/GPT2_M/e2e/predict.1050.b10p08r4.jsonl - 2025-03-25 21:52:40,928 - log
finish inference - 2025-03-25 21:52:40,929 - log
